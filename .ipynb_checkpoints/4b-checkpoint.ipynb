{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3841f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ce0a1",
   "metadata": {},
   "source": [
    "Creating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fb77844",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "study_hours = np.random.randint(3,8,100)\n",
    "marks_scored = np.random.randint(40,100,100)\n",
    "result = np.where(study_hours + marks_scored > 80, 1, 0)\n",
    "X = np.column_stack((study_hours, marks_scored))\n",
    "y = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d356e7ef",
   "metadata": {},
   "source": [
    "Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc63dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a814e5",
   "metadata": {},
   "source": [
    "Trying out different classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d805b",
   "metadata": {},
   "source": [
    "1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "789f21b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "result1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b1d74",
   "metadata": {},
   "source": [
    "2. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e698c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model2 = DecisionTreeClassifier()\n",
    "model2.fit(X_train, y_train)\n",
    "result2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a15326",
   "metadata": {},
   "source": [
    "3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2646b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model3 = SVC()\n",
    "model3.fit(X_train, y_train)\n",
    "result3 = model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b90e84",
   "metadata": {},
   "source": [
    "Printing out the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9ac1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3798241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Logistic Regression\n",
      "Confusion Matrix = \n",
      " [[16  0]\n",
      " [ 0  4]]\n",
      "Accuracy =  1.0\n",
      "Precision =  1.0\n",
      "Recall =  1.0\n",
      "F1-Score =  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"1. Logistic Regression\")\n",
    "print(\"Confusion Matrix = \\n\", confusion_matrix(result1, y_test))\n",
    "print(\"Accuracy = \", accuracy_score(result1, y_test))\n",
    "print(\"Precision = \", precision_score(result1, y_test))\n",
    "print(\"Recall = \", recall_score(result1, y_test))\n",
    "print(\"F1-Score = \", f1_score(result1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fa7cb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Decision Tree\n",
      "Confusion Matrix = \n",
      " [[16  0]\n",
      " [ 0  4]]\n",
      "Accuracy =  1.0\n",
      "Precision =  1.0\n",
      "Recall =  1.0\n",
      "F1-Score =  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"2. Decision Tree\")\n",
    "print(\"Confusion Matrix = \\n\", confusion_matrix(result2, y_test))\n",
    "print(\"Accuracy = \", accuracy_score(result2, y_test))\n",
    "print(\"Precision = \", precision_score(y_test, result2))\n",
    "print(\"Recall = \", recall_score(result2, y_test))\n",
    "print(\"F1-Score = \", f1_score(result2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1566e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. SVC\n",
      "Confusion Matrix = \n",
      " [[16  1]\n",
      " [ 0  3]]\n",
      "Accuracy =  0.95\n",
      "Precision =  0.75\n",
      "Recall =  1.0\n",
      "F1-Score =  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"3. SVC\")\n",
    "print(\"Confusion Matrix = \\n\", confusion_matrix(result3, y_test))\n",
    "print(\"Accuracy = \", accuracy_score(result3, y_test))\n",
    "print(\"Precision = \", precision_score(result3, y_test))\n",
    "print(\"Recall = \", recall_score(result3, y_test))\n",
    "print(\"F1-Score = \", f1_score(result3, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
